{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb40170",
   "metadata": {},
   "source": [
    "# Graded Lab : Tool Use and Reflective Agents\n",
    "\n",
    "In this lab, you will explore how AI agents can enhance research workflows by leveraging external tools and engaging in critical self-reflection. You'll learn how to build and integrate callable toolsâ€”such as web and academic search functions, and connect them to a language model using OpenAI's tool-calling API. Then, youâ€™ll guide the agent to not only generate content but also **reflect** on its own output, improving the quality and depth of the final report. By the end of this lab, you will have implemented a mini agent capable of searching, reasoning, and publishing structured reports in HTMLâ€”laying the foundation for more advanced multi-step and autonomous AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ede51",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this lab, you can:\n",
    "- Chain steps into a research pipeline (**search â†’ reflection â†’ formatting**).\n",
    "- Convert natural-language output into **styled HTML** suitable for sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd08fc44",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to write your solution code or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "* To submit your notebook for grading, first save it by clicking the ðŸ’¾ icon on the top left of the page and then click on the <span style=\"background-color: red; color: white; padding: 3px 5px; font-size: 16px; border-radius: 5px;\">Submit assignment</span> button on the top right of the page.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22668fb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 421,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Standard library imports\n",
    "# ================================\n",
    "import json\n",
    "\n",
    "# ================================\n",
    "# Third-party imports\n",
    "# ================================\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# ================================\n",
    "# Local / project imports\n",
    "# ================================\n",
    "import research_tools\n",
    "\n",
    "# ================================\n",
    "# Environment setup\n",
    "# ================================\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Instantiate OpenAI's client (you should use this in your graded functions)\n",
    "CLIENT = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe40a79",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 30
   },
   "outputs": [],
   "source": [
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c1bef",
   "metadata": {},
   "source": [
    "## Using Tools\n",
    "\n",
    "Youâ€™ll use two research tools exposed in the `research_tools` module:\n",
    "- **`arxiv_search_tool(query, max_results)`** â€“ academic papers via arXiv API.\n",
    "- **`tavily_search_tool(query, max_results, include_images)`** â€“ general web search via Tavily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacac323",
   "metadata": {},
   "source": [
    "Let's explore how the `arxiv_search_tool` works.\n",
    "\n",
    "This tool searches arXiv and returns a list of papers with:\n",
    "- `title`, `authors`, `published`, `summary`, `url`, and (if available) `link_pdf`.\n",
    "\n",
    "Below, we run a quick test and print the results in a readable format. Next cell is editable so feel free to try some search queries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d0eded",
   "metadata": {
    "deletable": false,
    "height": 336
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Paper 1\n",
      "  Title     : Linear Mappings of Free Algebra\n",
      "  Authors   : Aleks Kleyn\n",
      "  Published : 2010-03-08\n",
      "  URL       : http://arxiv.org/abs/1003.1544v2\n",
      "\n",
      "ðŸ“„ Paper 2\n",
      "  Title     : Non-linear positive maps between $C^*$-algebras\n",
      "  Authors   : Ali Dadkhah, Mox Sal Moslehian\n",
      "  Published : 2018-11-07\n",
      "  URL       : http://arxiv.org/abs/1811.03128v1\n",
      "\n",
      "ðŸ“„ Paper 3\n",
      "  Title     : GrÃ¼ss type inequalities for positive linear maps on $C^*$-algebras\n",
      "  Authors   : Ali Dadkhah, Mohammad Sal Moslehian\n",
      "  Published : 2016-10-12\n",
      "  URL       : http://arxiv.org/abs/1610.03868v1\n",
      "\n",
      "\n",
      "ðŸ§¾ Raw arxiv_Results:\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"title\": \"Linear Mappings of Free Algebra\",\n",
      "    \"authors\": [\n",
      "      \"Aleks Kleyn\"\n",
      "    ],\n",
      "    \"published\": \"2010-03-08\",\n",
      "    \"url\": \"http://arxiv.org/abs/1003.1544v2\",\n",
      "    \"summary\": \"For arbitrary F-algebra, in which the operation of addition is defined, I explore biring of matrices of mappings. The sum of matrices is determined by the sum in F-algebra, and the product of matrices is determined by the product of mappings. The system of equations, whose matrix is a matrix of mappings, is called a system of additive equations. I considered the methods of solving system of additive equations. As an example, I consider the solution of a system of linear equations over the complex field provided that the equations contain unknown quantities and their conjugates.\\n  Linear mappings of algebra over a commutative ring preserve the operation of addition in algebra and the product of elements of the algebra by elements of the ring. The representation of tensor product A\\\\otimes A in algebra A generates the set of linear transformations of algebra A.\\n  The results of this research will be useful for mathematicians and physicists who deal with different algebras.\",\n",
      "    \"link_pdf\": \"https://arxiv.org/pdf/1003.1544v2\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Non-linear positive maps between $C^*$-algebras\",\n",
      "    \"authors\": [\n",
      "      \"Ali Dadkhah\",\n",
      "      \"Mox Sal Moslehian\"\n",
      "    ],\n",
      "    \"published\": \"2018-11-07\",\n",
      "    \"url\": \"http://arxiv.org/abs/1811.03128v1\",\n",
      "    \"summary\": \"We present some properties of (not necessarily linear) positive maps between $C^*$-algebras. We first extend the notion of Lieb functions to that of Lieb positive maps between $C^*$-algebras. Then we give some basic properties and fundamental inequalities related to such maps. Next, we study $n$-positive maps ($n\\\\geq 2$). We show that if for a unital $3$-positive map $\\u03a6: \\\\mathscr{A}\\\\longrightarrow\\\\mathscr{B}$ between unital $C^*$-algebras and some $ A\\\\in \\\\mathscr{A}$ equality $\\u03a6(A^*A)= \\u03a6(A)^* \\u03a6(A)$ holds, then $\\u03a6(XA)=\\u03a6(X)\\u03a6(A)$ for all $X \\\\in \\\\mathscr{A}$. In addition, we prove that for a certain class of unital positive maps $\\u03a6: \\\\mathscr{A}\\\\longrightarrow\\\\mathscr{B}$ between unital $C^*$-algebras, the inequality $\\u03a6(\\u03b1A)\\\\leq\\u03b1\\u03a6(A)$ holds for all $ \\u03b1\\\\in [0,1]$ and all positive elements $ A\\\\in \\\\mathscr{A}$ if and only if $\\u03a6(0)=0$. Furthermore, we show that if for some $\\u03b1$ in the unit ball of $\\\\mathbb{C}$ or in $\\\\mathbb{R}_+$ with $|\\u03b1|\\\\neq 0,1$, the equality $\\u03a6(\\u03b1I)=\\u03b1I$ holds, then $\\u03a6$ is additive on positive elements of $\\\\mathscr{A}$. Moreover, we present a mild condition for a $6$-positive map, which ensures its linearity.\",\n",
      "    \"link_pdf\": \"https://arxiv.org/pdf/1811.03128v1\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Gr\\u00fcss type inequalities for positive linear maps on $C^*$-algebras\",\n",
      "    \"authors\": [\n",
      "      \"Ali Dadkhah\",\n",
      "      \"Mohammad Sal Moslehian\"\n",
      "    ],\n",
      "    \"published\": \"2016-10-12\",\n",
      "    \"url\": \"http://arxiv.org/abs/1610.03868v1\",\n",
      "    \"summary\": \"Let $\\\\mathcal{A}$ and $\\\\mathcal{B}$ be two unital $C^*$-algebras and let for $C\\\\in\\\\mathcal{A},\\\\ \\u0393_C=\\\\{\\u03b3\\\\in \\\\mathbb{C} : \\\\|C-\\u03b3I\\\\|=\\\\inf_{\\u03b1\\\\in \\\\mathbb{C}} \\\\|C-\\u03b1I\\\\|\\\\}$. We prove that if $\\u03a6:\\\\mathcal{A} \\\\longrightarrow \\\\mathcal{B}$ is a unital positive linear map, then \\\\begin{eqnarray*} \\\\big|\\u03a6(AB)-\\u03a6(A)\\u03a6(B)\\\\big| \\\\leq \\\\big\\\\|\\u03a6(|A^*-\\u03b6I|^2)\\\\big\\\\|^\\\\frac{1}{2} \\\\big[\\u03a6(|B-\\u03beI|^2)\\\\big]^\\\\frac{1}{2} \\\\end{eqnarray*} for all $A,B\\\\in\\\\mathcal{A}, \\u03b6\\\\in \\u0393_A$ and $\\u03be\\\\in\\u0393_B.$\\\\\\\\ In addition, we show that if $(\\\\mathcal{A},\\u03c4)$ is a noncommutative probability space and $T \\\\in \\\\mathcal{A}$ is a density operator, then \\\\begin{eqnarray*} \\\\ \\\\ \\\\big|\\u03c4(TAB)-\\u03c4(TA)\\u03c4(TB)\\\\big|\\\\leq \\\\|A-\\u03b6I\\\\|_p\\\\|B-\\u03beI\\\\|_q\\\\|T\\\\|_r \\\\ \\\\ (p,q\\\\geq 4, r\\\\geq 2) \\\\end{eqnarray*} and \\\\begin{eqnarray*} \\\\big|\\u03c4(TAB)-\\u03c4(TA)\\u03c4(TB)\\\\big|\\\\leq \\\\|A-\\u03b6I\\\\|_p\\\\|B-\\u03beI\\\\|_q\\\\|T\\\\| \\\\ \\\\ \\\\ \\\\ (p,q\\\\geq 2)\\\\ \\\\ \\\\ \\\\ \\\\ \\\\end{eqnarray*} for every $A,B \\\\in \\\\mathcal{A}$ and $\\u03b6\\\\in \\u0393_A,\\u03be\\\\in \\u0393_B$. Our results generalize the corresponding results for matrices to operators on spaces of arbitrary dimension.\",\n",
      "    \"link_pdf\": \"https://arxiv.org/pdf/1610.03868v1\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test the arXiv search tool\n",
    "topic = \"linear algebra\"\n",
    "\n",
    "arxiv_results = research_tools.arxiv_search_tool(topic, max_results=3)\n",
    "\n",
    "# Show formatted arxiv_results\n",
    "for i, paper in enumerate(arxiv_results, 1):\n",
    "    if \"error\" in paper:\n",
    "        print(f\"âŒ Error: {paper['error']}\")\n",
    "    else:\n",
    "        print(f\"ðŸ“„ Paper {i}\")\n",
    "        print(f\"  Title     : {paper['title']}\")\n",
    "        print(f\"  Authors   : {', '.join(paper['authors'])}\")\n",
    "        print(f\"  Published : {paper['published']}\")\n",
    "        print(f\"  URL       : {paper['url']}\\n\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ§¾ Raw arxiv_Results:\\n\")\n",
    "print(json.dumps(arxiv_results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fd399",
   "metadata": {},
   "source": [
    "The `tavily_search_tool` calls the Tavily API to fetch web results. Returns a list of dicts:\n",
    "- `title`, `content`, `url` (and optional image URLs when `include_images=True`).\n",
    "\n",
    "Run the cell to inspect sample output. Next cell is editable so feel free to try some search queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6e728e",
   "metadata": {
    "deletable": false,
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'What is Retrieval Augmented Generation (RAG)?', 'content': '* Learn how retrieval augmented generation (RAG) works by combining large language models (LLMs) with real-time, external data for more accurate and relevant outputs. Retrieval augmented generation (RAG) is a hybrid AI framework that bolsters large language models (LLMs) by combining them with external, up-to-date data sources. Instead of relying solely on static training data, RAG retrieves relevant documents at query time and feeds them into the model as context. This process flow helps developers update data sources without retraining the model and makes RAG a scalable and cost-effective solution for building LLM applications in domains like customer support, knowledge bases and internal search. This is called retrieval augmented generation (RAG), as you would retrieve the relevant data and use it as augmented context for the LLM. With RAG architecture, organizations can deploy any LLM model and augment it to return relevant results for their organization by giving it a small amount of their data without the costs and time of fine-tuning or pretraining the model.', 'url': 'https://www.databricks.com/glossary/retrieval-augmented-generation-rag'}\n",
      "{'title': 'Retrieval-augmented generation', 'content': 'Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information.', 'url': 'https://en.wikipedia.org/wiki/Retrieval-augmented_generation'}\n",
      "{'title': 'Retrieval-Augmented Generation (RAG)', 'content': \"Retrieval-augmented generation, or RAG, is a technique that uses authoritative, external data to improve the accuracy, relevancy, and usefulness of a model's\", 'url': 'https://www.pinecone.io/learn/retrieval-augmented-generation/'}\n",
      "{'title': 'Top Use Cases of Retrieval-Augmented Generation (RAG) in AI', 'content': \"* By integrating retrieval mechanisms with language generation, RAG systems produce more accurate and informative text outputs, significantly improving tasks like machine translation, question answering, and summarization. Retrieval augmented generation (RAG) is an artificial intelligence methodology that combines the power of neural language models with external knowledge resources to generate text that is relevant and informed. Retrieval augmented generation (RAG) operates by integrating a retrieval component into the language generation process, expanding the model's knowledge base beyond its initial training data. Retrieval augmented generation (RAG) significantly enhances the capabilities of natural language processing systems. For **question answering**, RAG employs its retrieval component to source relevant information before generating a response. Retrieval-augmented generation (RAG) technology significantly improves the responsiveness and accuracy of conversational agents. Retrieval augmented generation has significantly enhanced the capabilities of information retrieval systems. In the domain of retrieval augmented generation systems, challenges such as bias in datasets, scalability of solutions, and ethical implications guide future work.\", 'url': 'https://www.glean.com/blog/retrieval-augmented-generation-use-cases'}\n",
      "{'title': 'What Is Retrieval-Augmented Generation aka RAG', 'content': 'Retrieval-augmented generation is a technique for enhancing the accuracy and reliability of generative AI models with information fetched from specific and', 'url': 'https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/'}\n"
     ]
    }
   ],
   "source": [
    "# Test the Tavily search tool\n",
    "topic = \"retrieval-augmented generation applications\"\n",
    "\n",
    "tavily_results = research_tools.tavily_search_tool(topic)\n",
    "for item in tavily_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7f628",
   "metadata": {},
   "source": [
    "## Tool Mapping\n",
    "\n",
    "In the next cell you will define a dictionary that maps tool names (strings) to the actual Python functions. This allows the model to call tools by name during tool-calling. This dictionary will be used in your first graded function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada2e9cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 98,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# Tool mapping\n",
    "TOOL_MAPPING = {\n",
    "    \"tavily_search_tool\": research_tools.tavily_search_tool,\n",
    "    \"arxiv_search_tool\": research_tools.arxiv_search_tool,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed9e5e",
   "metadata": {},
   "source": [
    "## Exercise 1: Generate Research Report with Tools\n",
    "**Goal:** Implement `generate_research_report_with_tools(prompt)`.\n",
    "In this exercise, you'll work on a function that generates a detailed research report with the assistance of online tools. Focus on setting up interaction with the language model and handling the responses effectively.\n",
    "\n",
    "## Key Hints\n",
    "\n",
    "### 1. Setting Up the Chat with the Language Model\n",
    "- **Tool Selection**: Ensure that the tools are automatically selected by the model. Look into how to set `tool_choice` to \"auto\" within the function call. A helpful resource can be found in [OpenAIâ€™s Function Calling Documentation](https://platform.openai.com/docs/guides/function-calling#tool-choice).\n",
    "- **Parameter Configuration**: Consider the parameters already defined in your function, such as model, messages, and tools. Think about how these might be used in your setup.\n",
    "\n",
    "### 2. Recording Tool Call Results\n",
    "- **Understanding the `ChatCompletionMessage`** object will help you access the required attributes to save the messages. An example of `ChatCompletionMessage` looks like this: \n",
    "\n",
    "```python\n",
    "ChatCompletionMessage(\n",
    "    content=None,\n",
    "    refusal=None,\n",
    "    role='assistant',\n",
    "    annotations=[],\n",
    "    audio=None,\n",
    "    function_call=None,\n",
    "    tool_calls=[\n",
    "        ChatCompletionMessageFunctionToolCall(\n",
    "            id='call_ymMki5TBB91efJhMPjgoqjop',\n",
    "            function=Function(\n",
    "                arguments='{\"query\":\"radio observations of recurrent novae\",\"max_results\":5}',\n",
    "                name='arxiv_search_tool'\n",
    "            ),\n",
    "            type='function'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "```\n",
    "Assuming that `msg` if of type `ChatCompletionMessage`, if you wanted to get the `name` of a `tool_call` you can do something like:\n",
    "```python\n",
    " for call in msg.tool_calls:\n",
    "    tool_name = call.function.name\n",
    "```\n",
    "Finally, the `result` variable will be created by actually calling the function associated with each tool (`tool_func`).\n",
    "\n",
    "By leveraging these hints, you'll work towards an implementation that enables robust data gathering and report generation through smart tool integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60ebc11",
   "metadata": {
    "deletable": false,
    "height": 1645,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: generate_research_report_with_tools\n",
    "def generate_research_report_with_tools(prompt: str, model: str = \"gpt-4o\") -> str:\n",
    "    \"\"\"\n",
    "    Generates a research report using OpenAI's tool-calling with arXiv and Tavily tools.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The user prompt.\n",
    "        model (str): OpenAI model name.\n",
    "\n",
    "    Returns:\n",
    "        str: Final assistant research report text.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a research assistant that can search the web and arXiv to write detailed, \"\n",
    "                \"accurate, and properly sourced research reports.\\n\\n\"\n",
    "                \"ðŸ” Use tools when appropriate (e.g., to find scientific papers or web content).\\n\"\n",
    "                \"ðŸ“š Cite sources whenever relevant. Do NOT omit citations for brevity.\\n\"\n",
    "                \"ðŸŒ When possible, include full URLs (arXiv links, web sources, etc.).\\n\"\n",
    "                \"âœï¸ Use an academic tone, organize output into clearly labeled sections, and include \"\n",
    "                \"inline citations or footnotes as needed.\\n\"\n",
    "                \"ðŸš« Do not include placeholder text such as '(citation needed)' or '(citations omitted)'.\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # List of available tools\n",
    "    tools = [research_tools.arxiv_tool_def, research_tools.tavily_tool_def]\n",
    "\n",
    "    # Maximum number of turns\n",
    "    max_turns = 10\n",
    "    \n",
    "    # Iterate for max_turns iterations\n",
    "    for _ in range(max_turns):\n",
    "\n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Chat with the LLM via the client and set the correct arguments. Hint: Their names match names of variables already defined.\n",
    "        # Make sure to let the LLM choose tools automatically. Hint: Look at the docs provided earlier!\n",
    "        response = CLIENT.chat.completions.create( \n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=1, \n",
    "        ) \n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Get the response from the LLM and append to messages\n",
    "        msg = response.choices[0].message \n",
    "        messages.append(msg) \n",
    "\n",
    "        # Stop when the assistant returns a final answer (no tool calls)\n",
    "        if not msg.tool_calls:      \n",
    "            final_text = msg.content\n",
    "            print(\"âœ… Final answer:\")\n",
    "            print(final_text)\n",
    "            break\n",
    "\n",
    "        # Execute tool calls and append results\n",
    "        for call in msg.tool_calls:\n",
    "            tool_name = call.function.name\n",
    "            args = json.loads(call.function.arguments)\n",
    "            print(f\"ðŸ› ï¸ {tool_name}({args})\")\n",
    "\n",
    "            try:\n",
    "                tool_func = TOOL_MAPPING[tool_name]\n",
    "                result = tool_func(**args)\n",
    "            except Exception as e:\n",
    "                result = {\"error\": str(e)}\n",
    "\n",
    "            ### START CODE HERE ###\n",
    "\n",
    "            # Keep track of tool use in a new message\n",
    "            new_msg = { \n",
    "                # Set role to \"tool\" (plain string) to signal a tool was used\n",
    "                \"role\": \"tool\",\n",
    "                # As stated in the markdown when inspecting the ChatCompletionMessage object \n",
    "                # every call has an attribute called id\n",
    "                \"tool_call_id\": call.id,\n",
    "                # The name of the tool was already defined above, use that variable\n",
    "                \"name\": tool_name,\n",
    "                # Pass the result of calling the tool to json.dumps\n",
    "                \"content\": json.dumps(result)\n",
    "            }\n",
    "\n",
    "            ### END CODE HERE ###\n",
    "\n",
    "            # Append to messages\n",
    "            messages.append(new_msg)\n",
    "\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee23d21",
   "metadata": {},
   "source": [
    "Run the following cell to check the correctness of your code. It might take a while so don't worry if it takes a couple of minutes to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af8aec5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ arxiv_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "ðŸ› ï¸ tavily_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "âœ… Final answer:\n",
      "## Radio Observations of Recurrent Novae\n",
      "\n",
      "Recurrent novae are a fascinating astronomical phenomenon where a white dwarf star in a binary system undergoes multiple nova eruptions over time. Radio observations have provided critical insights into the mass ejection, velocity, and other characteristics of these novae. Below is a summary of key radio observations on several recurrent novae:\n",
      "\n",
      "### T Pyxidis\n",
      "T Pyx is a well-studied recurrent nova, albeit an unusual one. A notable study conducted during the 2011 outburst used radio observations to investigate the dynamics of its ejecta. The findings indicated that the radio flux was initially low, rising significantly only after about 50 days. This suggested that the radio-emitting material was either very cold or expanding slowly. The study estimated a significant mass ejection, about \\(1-30 \\times 10^{-5} M_\\odot\\), which is notably higher than typical for recurrent novae [source](https://ui.adsabs.harvard.edu/abs/2014ApJ...785...78N).\n",
      "\n",
      "### RS Ophiuchi\n",
      "RS Ophiuchi is one of the most well-documented recurrent novae with respect to radio emissions. Several key observations have been made across its multiple outbursts:\n",
      "\n",
      "1. **1985 Outburst**: This event was the first recorded instance of a radio detection associated with a recurrent nova event. The rapid expansion of the radio source was observed, suggesting a velocity of up to 4200 km/s. The radio emissions, likely synchrotron radiation, provided insights into the dynamics of the expanding nova shell [source](http://ui.adsabs.harvard.edu/abs/1986ApJ...305L..71H/abstract).\n",
      "\n",
      "2. **2021 Outburst**: More recent observations during the 2021 outburst included low-frequency radio studies, offering further insights into the magnetic fields and particle acceleration processes associated with such explosive events [source](https://academic.oup.com/mnras/article/523/1/132/7159730).\n",
      "\n",
      "### V3890 Sagittarii\n",
      "The recurrent nova V3890 Sgr exhibits radio emissions observable across several wavelengths, extending from radio to gamma rays. These emissions provide a comprehensive view of the physical processes occurring during the eruptions, aiding in the understanding of the recurrence and energy release mechanisms in such systems [source](https://pos.sissa.it/460/037/).\n",
      "\n",
      "### General Insights\n",
      "Radio observations across different recurrent novae consistently reveal that these systems can have complex and varied ejecta dynamics, with mass ejections and velocities varying significantly from one nova to another. The non-thermal nature of radio emissions, often delayed relative to optical outbursts, indicates complex interactions in the nova environment, including shock interactions and delayed energy release.\n",
      "\n",
      "Overall, radio studies continue to be an invaluable tool in expanding our understanding of recurrent novae, providing details not easily accessible through optical observations alone.\n",
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_generate_research_report_with_tools(generate_research_report_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb162d",
   "metadata": {},
   "source": [
    "## Exercise 2: Reflection + Rewrite\n",
    "\n",
    "**Goal:** Implement `reflection_and_rewrite(report)`.\n",
    "\n",
    "In this task, your goal is to develop a function that takes a report, analyzes it, generates a structured reflection, and produces an improved version of the report. This involves two main tasks: crafting a precise prompt and setting up a correctly configured response call to the language model.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "### 1. Create a User Prompt\n",
    "\n",
    "- **Objective**: Guide the language model to output a structured response in JSON format.\n",
    "- **Format**: Ensure the output includes two keys, `\"reflection\"` and `\"revised_report\"`.\n",
    "- **Details**: Your reflection should cover strengths, limitations, suggestions, and opportunities. The revised report should incorporate these elements to improve clarity and academic tone.\n",
    "\n",
    "### 2. Configure the Response Call\n",
    "\n",
    "- **Parameters**: Use the specified model (e.g., `\"gpt-4o-mini\"`) and set the temperature equal to the `temperature` parameter of the graded function.\n",
    "- **Structure**: Make sure the response setup directs the model properly, ensuring the JSON format is adhered to without additional commentary.\n",
    "\n",
    "\n",
    "By implementing these steps, your function will effectively transform and improve the given reports. Handle JSON parsing carefully to ensure the output is valid and reliable. Happy coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4585bcc6",
   "metadata": {
    "deletable": false,
    "height": 880,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reflection_and_rewrite\n",
    "def reflection_and_rewrite(report, model: str = \"gpt-4o-mini\", temperature: float = 0.3) -> dict:\n",
    "    \"\"\"\n",
    "    Generates a structured reflection AND a revised research report.\n",
    "    Accepts raw text OR the messages list returned by generate_research_report_with_tools.\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "          - \"reflection\": structured reflection text\n",
    "          - \"revised_report\": improved version of the input report\n",
    "    \"\"\"\n",
    "\n",
    "    # Input can be plain text or a list of messages, this function detects and parses accordingly\n",
    "    report = research_tools.parse_input(report)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the prompt. A multi-line f-string is typically used for this.\n",
    "    # Remember it should ask the model to output ONLY valid JSON with this structure:\n",
    "    # {{ \"reflection\": \"<text>\", \"revised_report\": \"<text>\" }}\n",
    "    user_prompt = f\"\"\"\n",
    "    Your goal is to take a report, analyze it, generates a structured reflection, and produces an improved \n",
    "    version of the report.\n",
    "    \n",
    "    Output a structured response in JSON format.Return STRICT JSON with two fields\n",
    "    Format: Ensure the output includes two keys, \"reflection\" and \"revised_report\".\n",
    "    {{\n",
    "    \"reflection\": \"<structured reflection text>\", \n",
    "    \"revised_report\": \"<improved version of the input report>\" \n",
    "    }}\n",
    "    \n",
    "    Report:\n",
    "    {report}\n",
    "    \n",
    "    Requirements: \n",
    "    Your reflection should cover strengths, limitations, suggestions, and opportunities. \n",
    "    The revised report should incorporate these elements to improve clarity and academic tone.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a response from the LLM\n",
    "    response = CLIENT.chat.completions.create( \n",
    "        # Pass in the model\n",
    "        model=model,\n",
    "        messages=[ \n",
    "            # System prompt is already defined\n",
    "            {\"role\": \"system\", \"content\": \"You are an academic reviewer and editor.\"},\n",
    "            # Add user prompt\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        # Set the temperature equal to the temperature parameter passed to the function\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Extract output\n",
    "    llm_output = response.choices[0].message.content.strip()\n",
    "\n",
    "    # Check if output is valid JSON\n",
    "    try:\n",
    "        data = json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(\"The output of the LLM was not valid JSON. Adjust your prompt.\")\n",
    "\n",
    "    return {\n",
    "        \"reflection\": str(data.get(\"reflection\", \"\")).strip(),\n",
    "        \"revised_report\": str(data.get(\"revised_report\", \"\")).strip(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a563b04",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_reflection_and_rewrite(reflection_and_rewrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210d211",
   "metadata": {},
   "source": [
    "## Exercise 3: Convert Report to HTML\n",
    "**Goal:** Implement `convert_report_to_html(report)`.\n",
    "This exercise focuses on transforming a plain text research report into a well-structured HTML document. You will build a function to facilitate this conversion using a language model.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "### 1. Create a User Prompt\n",
    "- **Objective**: Instruct the model to transform plain text into HTML structure.\n",
    "- **Format**: Ensure the output is valid, clean HTML with appropriate section headers, formatted paragraphs, and clickable links.\n",
    "- **Details**: Preserve the citation style and request that the model responds only with HTML, without additional commentary.\n",
    "\n",
    "### 2. Configure the Response Call\n",
    "- **Parameters**: Use the specified model (e.g., `\"gpt-4o\"`) and set an appropriate temperature to balance creativity and accuracy.\n",
    "- **Structure**: Configure the `CLIENT.chat.completions.create` call properly, using both system and user prompts to ensure a clear and focused task description.\n",
    "\n",
    "By following these steps, you'll effectively convert plaintext reports into formatted HTML documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7548464",
   "metadata": {
    "deletable": false,
    "height": 489,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convert_report_to_html\n",
    "def convert_report_to_html(report, model: str = \"gpt-4o\", temperature: float = 0.5) -> str:\n",
    "    \"\"\"\n",
    "    Converts a plaintext research report into a styled HTML page using OpenAI.\n",
    "    Accepts raw text OR the messages list from the tool-calling step.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input can be plain text or a list of messages, this function detects and parses accordingly\n",
    "    report = research_tools.parse_input(report)\n",
    "\n",
    "    # System prompt is already provided\n",
    "    system_prompt = \"You convert plaintext reports into full clean HTML documents.\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Build the user prompt instructing the model to return ONLY valid HTML\n",
    "    user_prompt = f\"\"\"\n",
    "    Goal : transforming a plain text research report into a well-structured HTML document.\n",
    "    \n",
    "    Output Format: \n",
    "    Ensure the output is valid, clean HTML with appropriate section headers, formatted paragraphs, and \n",
    "    clickable links.\n",
    "    \n",
    "    Report:\n",
    "    {report}\n",
    "    \n",
    "    Instructions : Preserve the citation style and request that the model responds only with HTML, \n",
    "    without additional commentary.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Call the LLM by interacting with the CLIENT. \n",
    "    # Remember to set the correct values for the model, messages (system and user prompts) and temperature\n",
    "    response = CLIENT.chat.completions.create( \n",
    "        # Pass in the model\n",
    "        model=model,\n",
    "        messages=[ \n",
    "            # System prompt is already defined\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            # Add user prompt\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        # Set the temperature equal to the temperature parameter passed to the function\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Extract the HTML from the assistant message\n",
    "    html = response.choices[0].message.content.strip()  \n",
    "\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe3c9c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_convert_report_to_html(convert_report_to_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f5e51",
   "metadata": {},
   "source": [
    "### ðŸš€ End-to-End Pipeline\n",
    "\n",
    "Run this cell to execute the full workflow:\n",
    "\n",
    "1. Generate a research report (tools).\n",
    "2. Reflect on the report.\n",
    "3. Convert the report to HTML.\n",
    "\n",
    "> You should see the rendered HTML below and two concise reflections in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f07e12e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 387
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ arxiv_search_tool({'query': 'radio observations of recurrent novae', 'max_results': 5})\n",
      "âœ… Final answer:\n",
      "### Radio Observations of Recurrent Novae: Overview\n",
      "\n",
      "Recurrent novae are a subclass of cataclysmic variables that undergo multiple nova outbursts. They consist of a white dwarf accreting matter from a companion star, leading to thermonuclear runaways. Studying these systems through radio observations can provide insights into their ejecta dynamics, mass ejection processes, and the circumstellar material.\n",
      "\n",
      "### Relevant Studies and Findings\n",
      "\n",
      "1. **V1723 Aql**:\n",
      "   - **Study**: \"Shocks and Ejecta Mass: Radio Observations of Nova V1723 Aql,\" by Jennifer H. S. Weston et al.\n",
      "   - **Summary**: The study focuses on the radio light curves of nova V1723 Aql, noting that they rise and fall over several months to years. One of the key findings is that the radio ejecta mass, determined through models, exceeds theoretical expectations. This discrepancy is explored using observations from the Karl G. Jansky Very Large Array (VLA). An unexpected initial bump in the radio light curve suggests the presence of shocks in the outer ejected shell, which fade over time [Weston et al., 2013](https://arxiv.org/pdf/1306.2265v2).\n",
      "\n",
      "2. **Lesson from Recurrent Novae**:\n",
      "   - **Study**: \"Lesson learned from (some) recurrent novae,\" by Elena Mason and Frederick M. Walters.\n",
      "   - **Summary**: This study presents spectra of recurrent novae YY Dor and nova LMC 2009, highlighting their similar spectral characteristics and suggesting a uniformity in the white dwarf progenitors and post-outburst phases among similar novae. The discussion emphasizes the common features found in these observations, which could give clues about the progenitor's properties and nova processes [Mason & Walters, 2013](https://arxiv.org/pdf/1303.2776v1).\n",
      "\n",
      "### Implications and Applications\n",
      "\n",
      "Radio astronomy offers a powerful tool for probing the physical conditions of novae. The observations can quantify ejecta masses, reveal shock interactions, and offer clues to the mass-loss history of these explosive events. These insights are crucial for understanding the lifecycle of recurrent novae and their influence on surrounding interstellar environments.\n",
      "\n",
      "Moreover, technological advancements, such as the improvements in the VLA, have enhanced the ability to capture detailed radio data, allowing more accurate models and theoretical predictions to be tested against observational results.\n",
      "\n",
      "In summary, radio observations of recurrent novae are vital for unraveling the complexities of these explosive systems and contribute to the broader understanding of stellar evolution and the dynamics of binary star systems.\n",
      "=== Research Report (preliminary) ===\n",
      "\n",
      "### Radio Observations of Recurrent Novae: Overview\n",
      "\n",
      "Recurrent novae are a subclass of cataclysmic variables that undergo multiple nova outbursts. They consist of a white dwarf accreting matter from a companion star, leading to thermonuclear runaways. Studying these systems through radio observations can provide insights into their ejecta dynamics, mass ejection processes, and the circumstellar material.\n",
      "\n",
      "### Relevant Studies and Findings\n",
      "\n",
      "1. **V1723 Aql**:\n",
      "   - **Study**: \"Shocks and Ejecta Mass: Radio Observations of Nova V1723 Aql,\" by Jennifer H. S. Weston et al.\n",
      "   - **Summary**: The study focuses on the radio light curves of nova V1723 Aql, noting that they rise and fall over several months to years. One of the key findings is that the radio ejecta mass, determined through models, exceeds theoretical expectations. This discrepancy is explored using observations from the Karl G. Jansky Very Large Array (VLA). An unexpected initial bump in the radio light curve suggests the presence of shocks in the outer ejected shell, which fade over time [Weston et al., 2013](https://arxiv.org/pdf/1306.2265v2).\n",
      "\n",
      "2. **Lesson from Recurrent Novae**:\n",
      "   - **Study**: \"Lesson learned from (some) recurrent novae,\" by Elena Mason and Frederick M. Walters.\n",
      "   - **Summary**: This study presents spectra of recurrent novae YY Dor and nova LMC 2009, highlighting their similar spectral characteristics and suggesting a uniformity in the white dwarf progenitors and post-outburst phases among similar novae. The discussion emphasizes the common features found in these observations, which could give clues about the progenitor's properties and nova processes [Mason & Walters, 2013](https://arxiv.org/pdf/1303.2776v1).\n",
      "\n",
      "### Implications and Applications\n",
      "\n",
      "Radio astronomy offers a powerful tool for probing the physical conditions of novae. The observations can quantify ejecta masses, reveal shock interactions, and offer clues to the mass-loss history of these explosive events. These insights are crucial for understanding the lifecycle of recurrent novae and their influence on surrounding interstellar environments.\n",
      "\n",
      "Moreover, technological advancements, such as the improvements in the VLA, have enhanced the ability to capture detailed radio data, allowing more accurate models and theoretical predictions to be tested against observational results.\n",
      "\n",
      "In summary, radio observations of recurrent novae are vital for unraveling the complexities of these explosive systems and contribute to the broader understanding of stellar evolution and the dynamics of binary star systems.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The output of the LLM was not valid JSON. Adjust your prompt.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 61\u001b[0m, in \u001b[0;36mreflection_and_rewrite\u001b[0;34m(report, model, temperature)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(preliminary_report)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 2) Reflection on the report (use the final TEXT to avoid ambiguity)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m reflection_text \u001b[38;5;241m=\u001b[39m \u001b[43mreflection_and_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreliminary_report\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# <-- pass text, not messages\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Reflection on Report ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(reflection_text[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreflection\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 63\u001b[0m, in \u001b[0;36mreflection_and_rewrite\u001b[0;34m(report, model, temperature)\u001b[0m\n\u001b[1;32m     61\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(llm_output)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output of the LLM was not valid JSON. Adjust your prompt.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflection\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mstrip(),\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevised_report\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevised_report\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mstrip(),\n\u001b[1;32m     68\u001b[0m }\n",
      "\u001b[0;31mException\u001b[0m: The output of the LLM was not valid JSON. Adjust your prompt."
     ]
    }
   ],
   "source": [
    "# 1) Research with tools\n",
    "prompt_ = \"Radio observations of recurrent novae\"\n",
    "preliminary_report = generate_research_report_with_tools(prompt_)\n",
    "print(\"=== Research Report (preliminary) ===\\n\")\n",
    "print(preliminary_report)\n",
    "\n",
    "# 2) Reflection on the report (use the final TEXT to avoid ambiguity)\n",
    "reflection_text = reflection_and_rewrite(preliminary_report)   # <-- pass text, not messages\n",
    "print(\"=== Reflection on Report ===\\n\")\n",
    "print(reflection_text['reflection'], \"\\n\")\n",
    "print(\"=== Revised Report ===\\n\")\n",
    "print(reflection_text['revised_report'], \"\\n\")\n",
    "\n",
    "\n",
    "# 3) Convert the report to HTML (use the TEXT and correct function name)\n",
    "html = convert_report_to_html(reflection_text['revised_report'])\n",
    "\n",
    "print(\"=== Generated HTML (preview) ===\\n\")\n",
    "print((html or \"\")[:600], \"\\n... [truncated]\\n\")\n",
    "\n",
    "# 4) Display full HTML\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00231efc",
   "metadata": {},
   "source": [
    "### ðŸ“Œ â€œExpected Outputâ€ note (for the notebook text cell)\n",
    "\n",
    "- `generate_research_report_with_tools` should return a **non-trivial string** (> 50 chars).\n",
    "\n",
    "- `reflection_and_rewrite` should return a **dict** with **'reflection'** and **'revised\\_report'** (both strings). The reflection should **mention** the four sections (Strengths, Limitations, Suggestions, Opportunities).\n",
    "\n",
    "- `convert_report_to_html` should return a **string that looks like HTML** (e.g., includes `<html>`, `<h1>`, `<p>`, or closing tags).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaad9ff",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Wrap-Up\n",
    "\n",
    "You built a mini research agent that can:\n",
    "- ðŸ”Ž call tools (arXiv + Tavily),\n",
    "- ðŸ§  reflect on its own output,\n",
    "- ðŸ“° publish a clean HTML report.\n",
    "\n",
    "Great job!\n",
    "\n",
    "### What to Submit\n",
    "- Your notebook with Exercise 1â€“3 completed.\n",
    "\n",
    "### Troubleshooting (quick)\n",
    "- **Model/tool-call loop stalls?** Lower `max_turns` or print intermediate messages.\n",
    "- **HTML looks odd?** Re-run conversion with a fresh assistant response.\n",
    "\n",
    "**Youâ€™re doneâ€”nice work!** ðŸš€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678071d",
   "metadata": {},
   "source": [
    "## Check grading feedback\n",
    "\n",
    "If you have collapsed the right panel to have more screen space for your code, as shown below:\n",
    "\n",
    "<img src=\"./images/collapsed.png\" alt=\"Collapsed Image\" width=\"800\" height=\"400\"/>\n",
    "\n",
    "You can click on the left-facing arrow button (highlighted in red) to view feedback for your submission after submitting it for grading. Once expanded, it should display like this:\n",
    "\n",
    "<img src=\"./images/expanded.png\" alt=\"Expanded Image\" width=\"800\" height=\"400\"/>"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
